{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3fcf41c-afdd-4101-a9db-c445931d2bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d3cbd6d-0a2b-4164-b903-f998375cc7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch torchvision datasets pillow scikit-learn matplotlib pandas tabulate tensorflow seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae1a1026-40d7-4c49-9f7b-dbe50865b202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | D:0.0763 G:0.8710\n",
      "Epoch 2/10 | D:0.0212 G:1.1340\n",
      "Epoch 3/10 | D:0.0148 G:1.1369\n",
      "Epoch 4/10 | D:0.0118 G:1.3158\n",
      "Epoch 5/10 | D:0.0179 G:1.6531\n",
      "Epoch 6/10 | D:0.0794 G:1.2651\n",
      "Epoch 7/10 | D:0.0216 G:1.3779\n",
      "Epoch 8/10 | D:0.0069 G:1.4262\n",
      "Epoch 9/10 | D:0.0058 G:1.3034\n",
      "Epoch 10/10 | D:0.1250 G:1.2882\n",
      "Train epoch 1/5\n",
      "Train epoch 2/5\n",
      "Train epoch 3/5\n",
      "Train epoch 4/5\n",
      "Train epoch 5/5\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       COVID-19     0.8571    0.9231    0.8889        13\n",
      "         Normal     0.9091    0.5882    0.7143        17\n",
      "Viral Pneumonia     0.7692    0.9524    0.8511        21\n",
      "\n",
      "       accuracy                         0.8235        51\n",
      "      macro avg     0.8452    0.8212    0.8181        51\n",
      "   weighted avg     0.8383    0.8235    0.8151        51\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset, random_split\n",
    "from torchvision import transforms, utils\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dataset and identify indices\n",
    "raw_ds = load_dataset(\"yuighj123/covid-19-classification\")\n",
    "class_names = raw_ds['train'].features['label'].names\n",
    "covid_idx = class_names.index('Covid')\n",
    "normal_idx = class_names.index('Normal')\n",
    "viral_idx = class_names.index('Viral Pneumonia')\n",
    "num_classes = len(class_names)\n",
    "\n",
    "def map_orig_label(l):\n",
    "    return l  \n",
    "\n",
    "# Real data Dataset (all 3 classes)\n",
    "class RealDataset(Dataset):\n",
    "    def __init__(self, hf_data, transform=None):\n",
    "        self.images = hf_data['image']\n",
    "        self.labels = hf_data['label']\n",
    "        self.transform = transform\n",
    "    def __len__(self): return len(self.labels)\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        if not isinstance(img, Image.Image): img = Image.fromarray(np.array(img))\n",
    "        img = img.convert('RGB')\n",
    "        if self.transform: img = self.transform(img)\n",
    "        return img, self.labels[idx]\n",
    "\n",
    "# Transforms\n",
    "tfm = transforms.Compose([\n",
    "    transforms.Resize((64,64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "real_ds = RealDataset(raw_ds['train'], transform=tfm)\n",
    "\n",
    "# Train LSGAN on minority classes only (Normal & Viral)\n",
    "latent_dim = 100\n",
    "img_shape = (3,64,64)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define simple LSGAN\n",
    "class G(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(latent_dim,128), nn.ReLU(True),\n",
    "            nn.Linear(128,256), nn.BatchNorm1d(256), nn.ReLU(True),\n",
    "            nn.Linear(256,512), nn.BatchNorm1d(512), nn.ReLU(True),\n",
    "            nn.Linear(512,np.prod(img_shape)), nn.Tanh()\n",
    "        )\n",
    "    def forward(self,z): return self.net(z).view(-1,*img_shape)\n",
    "\n",
    "class D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(np.prod(img_shape),512), nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512,256), nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256,1)\n",
    "        )\n",
    "    def forward(self,x): return self.net(x.view(x.size(0),-1))\n",
    "\n",
    "G_model = G().to(device)\n",
    "D_model = D().to(device)\n",
    "optG = optim.Adam(G_model.parameters(), lr=2e-4, betas=(0.5,0.999))\n",
    "optD = optim.Adam(D_model.parameters(), lr=2e-4, betas=(0.5,0.999))\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "def get_minority_loader():\n",
    "    \n",
    "    subset = torch.utils.data.Subset(real_ds,\n",
    "        [i for i,(img,lbl) in enumerate(real_ds) if lbl in [normal_idx, viral_idx]])\n",
    "    return DataLoader(subset, batch_size=64, shuffle=True)\n",
    "\n",
    "loader = get_minority_loader()\n",
    "for epoch in range(10):\n",
    "    for imgs,l in loader:\n",
    "        bs=imgs.size(0)\n",
    "        real = imgs.to(device)\n",
    "        valid = torch.ones(bs,1,device=device)\n",
    "        fake_label = torch.zeros(bs,1,device=device)\n",
    "        # train D\n",
    "        z = torch.randn(bs,latent_dim,device=device)\n",
    "        fake = G_model(z)\n",
    "        lossD = 0.5*(criterion(D_model(real),valid)+criterion(D_model(fake.detach()),fake_label))\n",
    "        optD.zero_grad(); lossD.backward(); optD.step()\n",
    "        # train G\n",
    "        lossG = criterion(D_model(fake),valid)\n",
    "        optG.zero_grad(); lossG.backward(); optG.step()\n",
    "    print(f\"Epoch {epoch+1}/10 | D:{lossD.item():.4f} G:{lossG.item():.4f}\")\n",
    "\n",
    "#  Generate synthetic for classes 1 &2 to balance all three\n",
    "counts = Counter([lbl for _,lbl in real_ds])\n",
    "max_cnt = max(counts.values())\n",
    "generated = []\n",
    "for target in [normal_idx, viral_idx]:\n",
    "    need = max_cnt - counts[target]\n",
    "    if need<=0: continue\n",
    "    z = torch.randn(need, latent_dim, device=device)\n",
    "    with torch.no_grad(): imgs = G_model(z).cpu()\n",
    "    for img in imgs: generated.append((img, target))\n",
    "\n",
    "# Save and wrap generated\n",
    "gen_dir = 'gen_imgs'; os.makedirs(gen_dir, exist_ok=True)\n",
    "for i,(img,lbl) in enumerate(generated):\n",
    "    utils.save_image(img, f\"{gen_dir}/img_{i}_lbl{lbl}.png\", normalize=True)\n",
    "class SynthDataset(Dataset):\n",
    "    def __init__(self, folder, tfm):\n",
    "        self.paths = [os.path.join(folder,f) for f in os.listdir(folder)]\n",
    "        self.tfm = tfm\n",
    "    def __len__(self): return len(self.paths)\n",
    "    def __getitem__(self,idx):\n",
    "        img = Image.open(self.paths[idx]).convert('RGB')\n",
    "        label = int(self.paths[idx].split('_lbl')[1].split('.png')[0])\n",
    "        return self.tfm(img), label\n",
    "synth_ds = SynthDataset(gen_dir, tfm)\n",
    "\n",
    "#  Combine real + synthetic, split 70/15/15\n",
    "full_ds = ConcatDataset([real_ds, synth_ds])\n",
    "train_n = int(0.7*len(full_ds))\n",
    "val_n = int(0.15*len(full_ds))\n",
    "test_n = len(full_ds)-train_n-val_n\n",
    "train_ds, val_ds, test_ds = random_split(full_ds, [train_n,val_n,test_n])\n",
    "load = lambda ds: DataLoader(ds, batch_size=64, shuffle=True)\n",
    "train_ld, val_ld, test_ld = load(train_ds), load(val_ds), load(test_ds)\n",
    "\n",
    "# Train CNN\n",
    "class CNN3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.feat = nn.Sequential(\n",
    "            nn.Conv2d(3,32,3,1,1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32,64,3,1,1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64,128,3,1,1), nn.ReLU(), nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.clf = nn.Sequential(nn.Flatten(), nn.Linear(128*8*8,128), nn.ReLU(), nn.Linear(128,num_classes))\n",
    "    def forward(self,x): return self.clf(self.feat(x))\n",
    "\n",
    "model = CNN3().to(device)\n",
    "opt = optim.Adam(model.parameters(),lr=1e-3)\n",
    "crit = nn.CrossEntropyLoss()\n",
    "for epoch in range(5):\n",
    "    model.train()\n",
    "    for x,y in train_ld:\n",
    "        x,y = x.to(device),y.to(device)\n",
    "        opt.zero_grad(); crit(model(x),y).backward(); opt.step()\n",
    "    print(f\"Train epoch {epoch+1}/5\")\n",
    "# Evaluate on test\n",
    "model.eval()\n",
    "all_p, all_t=[],[]\n",
    "with torch.no_grad():\n",
    "    for x,y in test_ld:\n",
    "        preds = model(x.to(device)).argmax(1).cpu()\n",
    "        all_p.append(preds); all_t.append(y)\n",
    "all_p,all_t=torch.cat(all_p),torch.cat(all_t)\n",
    "print(classification_report(all_t,all_p,labels=[covid_idx,normal_idx,viral_idx],\n",
    "                             target_names=['COVID-19','Normal','Viral Pneumonia'],digits=4))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
